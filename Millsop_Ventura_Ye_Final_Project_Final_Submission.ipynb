{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_gender_bkts.csv\n",
      "countries.csv\n",
      "sample_submission_NDF.csv\n",
      "sessions.csv\n",
      "test_users.csv\n",
      "train_users_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Import data files from Kaggle.\n",
    "DATA_PATH = './data/extracted'\n",
    "dfs_raw = {}\n",
    "dfs = {}\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        dfs_raw[file.split('.')[0]] = pd.read_csv(f'{DATA_PATH}/{file}')\n",
    "        dfs = dfs_raw.copy()\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDF      124543\n",
      "US        62376\n",
      "other     10094\n",
      "FR         5023\n",
      "IT         2835\n",
      "GB         2324\n",
      "ES         2249\n",
      "CA         1428\n",
      "DE         1061\n",
      "NL          762\n",
      "AU          539\n",
      "PT          217\n",
      "Name: country_destination, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split training dataset into data and labels.\n",
    "train_data_all = dfs[\"train_users_2\"]\n",
    "train_labels_all = dfs[\"train_users_2\"].iloc[:, -1:]\n",
    "\n",
    "# Evaluate existing representation of classes.\n",
    "print(pd.value_counts(train_labels_all['country_destination']))\n",
    "countries = train_labels_all['country_destination'].unique()\n",
    "\n",
    "# Create pd for each country.\n",
    "train_data_country = {}\n",
    "train_labels_country = {}\n",
    "min_count = -1\n",
    "for country in countries:\n",
    "    train_data_country[country] = train_data_all.loc[train_labels_all['country_destination'] == country]\n",
    "    train_labels_country[country] = train_labels_all.loc[train_labels_all['country_destination'] == country]\n",
    "    count = train_labels_country[country].shape[0]\n",
    "    if (min_count == -1 or count < min_count):\n",
    "        min_count = count\n",
    "\n",
    "# Create balanced training dataset.\n",
    "balanced_train_data = pd.DataFrame(columns=train_data_all.columns.values)\n",
    "for country in countries:\n",
    "    country_pd = train_data_country[country].sample(n=min_count, random_state=1)\n",
    "    balanced_train_data = pd.concat([balanced_train_data, country_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into data and labels (panda dataframes).\n",
    "#reduced this to 10k / 213k since it was taking forever to even test anything\n",
    "#train_data   = dfs[\"train_users_2\"][:10000].iloc[:, 0:-1] #we should randomize since accounts are in chronological order\n",
    "#train_labels = dfs[\"train_users_2\"][:10000][\"country_destination\"].ravel()\n",
    "\n",
    "# Set train/dev split to 0.04685/0.95315 to give train size of 10k.  0.04685 = 10000/213451\n",
    "test_size = 0.95315\n",
    "\n",
    "# Use (train_test_split) to randomize train_users_2 before splitting into train/dev.\n",
    "train_data, dev_data, train_labels, dev_labels = train_test_split(dfs[\"train_users_2\"].iloc[:, 0:-1], dfs[\"train_users_2\"].iloc[:, -1:], test_size=test_size, random_state=42)\n",
    "\n",
    "# Final test data for Kaggle submission.\n",
    "test_data = dfs[\"test_users\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to bucket ages prior to one-hot encoding\n",
    "def age_bucketer(df_input):\n",
    "    df = df_input\n",
    "    df.loc[(pd.isnull(df.age), 'age_bucket')] = 'unknown'\n",
    "    df.loc[(pd.notnull(df.age), 'age_bucket')] = pd.cut(df['age'],\n",
    "                                                        [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 74, 79, 84, 89, 94,99,10000],\n",
    "                                                        labels=['0-4', '5-9', '10-14','15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49',\n",
    "                                                                '50-54', '55-59','60-64', '65-69','70-74','75-79','80-84','85-89','90-94','95-99','100+'],\n",
    "                                                        include_lowest=True)\n",
    "    return df.drop(['age'], axis=1)\n",
    "\n",
    "#Since NaN's in categorical data will cause issues with our pipeline we will replace that with \"unknown\".\n",
    "def clean_first_affiliate_tracked_nulls(df_input):\n",
    "    df_input['first_affiliate_tracked'] = df_input['first_affiliate_tracked'].fillna(\"unknown\", inplace=False)\n",
    "    return df_input\n",
    "\n",
    "#Add month and year features\n",
    "def feature_creator (df_input):\n",
    "    df = df_input\n",
    "    df['first_active_date'] = pd.to_datetime(df.timestamp_first_active,format='%Y%m%d%H%M%S')\n",
    "    df['year_first_active'] = df['first_active_date'].dt.year\n",
    "    df['month_first_active'] = df['first_active_date'].dt.month\n",
    "    df['season'] = ''\n",
    "    df.loc[(df['month_first_active'].isin([12, 1, 2]), 'season')] = 'Winter'\n",
    "    df.loc[(df['month_first_active'].isin([3, 4, 5]), 'season')] = 'Spring'\n",
    "    df.loc[(df['month_first_active'].isin([6, 7, 8]), 'season')] = 'Summer'\n",
    "    df.loc[(df['month_first_active'].isin([9, 10, 11]), 'season')] = 'Fall'\n",
    "    return df.drop(['first_active_date'], axis=1) #consider dropping month as well\n",
    "\n",
    "def session_feature_creator(df_input):\n",
    "    df = df_input\n",
    "    session_agg = dfs['sessions'].groupby('user_id').agg({\"secs_elapsed\": np.sum, \"device_type\": pd.Series.nunique, 'action': 'count'}).reset_index(\n",
    "        ).rename(columns={'secs_elapsed':'total_time', 'device_type':'unique_device_types', 'action': 'unique_actions'})\n",
    "    return df.merge(session_agg, left_on='id', right_on='user_id', how='left')\n",
    "\n",
    "def nan_destroyer(df_input):\n",
    "    # funcation to remove nans from numerical fields, need to determine strategy\n",
    "    return none\n",
    "\n",
    "def feautre_selector(df_input):\n",
    "    # final function to remove IDs, repetitive features, and any features we do not want to be passed to our models\n",
    "    return none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Preprocessor pipeline.\n",
    "def create_preprocessor_pipeline():\n",
    "\n",
    "    column_transformer = make_column_transformer(\n",
    "        (['gender',\n",
    "          'signup_method',\n",
    "          'signup_flow',\n",
    "          'language',\n",
    "          'affiliate_channel',\n",
    "          'affiliate_provider',\n",
    "          'first_affiliate_tracked',\n",
    "          'signup_app',\n",
    "          'first_device_type',\n",
    "          'first_browser',\n",
    "          'age_bucket',\n",
    "          'season'\n",
    "         ], OneHotEncoder(handle_unknown='ignore')),remainder='drop') # when we add in sessions features we will want to pass remainders\n",
    "    \n",
    "    preprocessor = make_pipeline(\n",
    "        FunctionTransformer(age_bucketer, validate=False),\n",
    "        FunctionTransformer(feature_creator, validate=False),\n",
    "        FunctionTransformer(clean_first_affiliate_tracked_nulls, validate=False),\n",
    "        column_transformer)\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:739: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Stage: Data Preprocessor.\n",
    "preprocessor = create_preprocessor_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "rf = RandomForestClassifier(n_jobs = -1)\n",
    "lr = LogisticRegression()\n",
    "xgb = XGBClassifier(nthread=-1)\n",
    "\n",
    "vc = VotingClassifier(estimators = [('bnb', bnb), ('rf', rf), ('lr', lr), ('xgb', xgb)], voting='hard')\n",
    "\n",
    "pipeline = make_pipeline(preprocessor, vc)\n",
    "\n",
    "final_model = cross_validate(pipeline, train_data, train_labels,\n",
    "                      scoring=[\"f1_weighted\"],\n",
    "                      return_train_score=True, cv=3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\sye\\AppData\\Local\\Continuum\\anaconda3\\envs\\mids-w203\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Score: 0.6292\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>train_f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.115521</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.566314</td>\n",
       "      <td>0.609902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.046488</td>\n",
       "      <td>0.781497</td>\n",
       "      <td>0.578050</td>\n",
       "      <td>0.602862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.231501</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.570322</td>\n",
       "      <td>0.604440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_f1_weighted  train_f1_weighted\n",
       "0  11.115521    0.868474          0.566314           0.609902\n",
       "1  11.046488    0.781497          0.578050           0.602862\n",
       "2  11.231501    0.909692          0.570322           0.604440"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show accuracy results.\n",
    "pipeline.fit(train_data, train_labels.values.ravel())\n",
    "score = pipeline.score(dev_data, dev_labels.values.ravel())\n",
    "print(\"Pipeline Score: %.4f\" %(score))\n",
    "display(pd.DataFrame(final_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRITTEN: kaggle_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test data to submit to Kaggle for scoring.\n",
    "predictions = pipeline.predict(test_data)\n",
    "\n",
    "# Save to csv\n",
    "final_csv = 'kaggle_submission.csv'\n",
    "predictions_pd = pd.DataFrame(data=predictions, columns=['country'])\n",
    "test_result = pd.concat([test_data['id'], predictions_pd], axis=1, sort=False)\n",
    "test_result.to_csv(final_csv, index=False)\n",
    "print(\"WRITTEN: %s\" %(final_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
