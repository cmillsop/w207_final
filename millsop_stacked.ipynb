{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked ensemble attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I use ML-Ensemble to create a stacked ensemble using classifiers from the work described in the \"Final_Submission\" notebook.  A requirements.txt file has also been added that should be compatible with this notebook.\n",
    "\n",
    "Work towards the end of the notebook is unfinished.  At last attempt I had successfully created a stacked ensemble, however I was modifying the parameters to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ml-ensemble.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "# Import libraries.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_gender_bkts.csv\n",
      "countries.csv\n",
      "sample_submission_NDF.csv\n",
      "sessions.csv\n",
      "test_users.csv\n",
      "train_users_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Import data files from Kaggle.\n",
    "DATA_PATH = './data/extracted'\n",
    "dfs_raw = {}\n",
    "dfs = {}\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        dfs[file.split('.')[0]] = pd.read_csv(f'{DATA_PATH}/{file}')\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToDatetime(series_input):\n",
    "    return pd.to_datetime(series_input,format='%Y%m%d%H%M%S', errors='coerce')\n",
    "\n",
    "#Function to bucket ages prior to one-hot encoding\n",
    "def getAgeBucket(df_input):\n",
    "    z = df_input.age\n",
    "    z = pd.to_numeric(df_input.age, errors='coerce')\n",
    "    return pd.cut(z,\n",
    "                    [0, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 74, 79, 84, 89, 94,99,10000],\n",
    "                    labels=['0-4', '5-9', '10-14','15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49',\n",
    "                            '50-54', '55-59','60-64', '65-69','70-74','75-79','80-84','85-89','90-94','95-99','100+'],\n",
    "                    include_lowest=True)\n",
    "\n",
    "def getCountryForAge(df_input):\n",
    "    z = df_input.age\n",
    "    z = pd.to_numeric(df_input.age, errors='coerce')\n",
    "\n",
    "#Add month and year features\n",
    "def getYearFirstActive(df_input):\n",
    "    return pd.Series(transformToDatetime(df_input.timestamp_first_active).dt.year, index=df_input.index)\n",
    "\n",
    "def getMonthFirstActive(df_input):\n",
    "    return pd.Series(transformToDatetime(df_input.timestamp_first_active).dt.month, index=df_input.index)\n",
    "\n",
    "def getSeason(df_input):\n",
    "    season = pd.Series(transformToDatetime(df_input.timestamp_first_active).dt.month, index=df_input.index)\n",
    "    season[season.isin([12, 1, 2])] = 'Winter'\n",
    "    season[season.isin([3, 4, 5])] = 'Spring'\n",
    "    season[season.isin([6, 7, 8])] = 'Summer'\n",
    "    season[season.isin([9, 10, 11])] = 'Fall'\n",
    "    return season\n",
    "\n",
    "def getSessionActivityCount(df_input):\n",
    "    return dfs['sessions'].groupby(['user_id']).size().reset_index(name='counts').set_index('user_id')\n",
    "\n",
    "\n",
    "    \n",
    "# add features to training and test data: stateful data mutations (ew)\n",
    "# attempted to use pipelines, column_transformer, function_transformer, feature_union\n",
    "# the features can't be arbitrarily included since function_transformer and column_transformer return ndarray's instead of dataframes\n",
    "\n",
    "def add_features(df_input):\n",
    "    engineered_data = df_input\n",
    "    engineered_data['age_bucket'] = getAgeBucket(engineered_data)\n",
    "    engineered_data['first_active_year'] = getYearFirstActive(engineered_data)\n",
    "    engineered_data['first_active_month'] = getMonthFirstActive(engineered_data)\n",
    "    engineered_data['season'] = getSeason(engineered_data)\n",
    "    engineered_data['activity_count'] = getSessionActivityCount(engineered_data)\n",
    "    return engineered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Preprocessor pipeline.\n",
    "def create_preprocessor_pipeline():\n",
    "    \n",
    "    categorical_columns_to_process = [\n",
    "        'gender',\n",
    "        'signup_method',\n",
    "        'signup_flow',\n",
    "        'language',\n",
    "        'affiliate_channel',\n",
    "        'affiliate_provider',\n",
    "        'first_affiliate_tracked',\n",
    "        'signup_app',\n",
    "        'first_device_type',\n",
    "        'first_browser',\n",
    "        'age_bucket',\n",
    "        'season',\n",
    "        'first_active_month',\n",
    "        'first_active_year'\n",
    "    ]\n",
    "    \n",
    "    numerical_columns_to_process = [\n",
    "        'activity_count'\n",
    "    ]\n",
    "    \n",
    "    return make_column_transformer(\n",
    "        (categorical_columns_to_process,\n",
    "         make_pipeline(\n",
    "             SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=\"unknown\"),\n",
    "             OneHotEncoder(handle_unknown='ignore')\n",
    "         )\n",
    "        ),\n",
    "        (numerical_columns_to_process,\n",
    "         make_pipeline(\n",
    "             SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "             StandardScaler()\n",
    "         )\n",
    "        ),\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "preprocessor = create_preprocessor_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = add_features(dfs[\"train_users_2\"].iloc[:, 0:-1].copy().set_index('id'))\n",
    "all_train_labels = dfs[\"train_users_2\"].iloc[:, -1:]\n",
    "all_test_data = add_features(dfs[\"test_users\"].copy().set_index('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/dev split to 0.04685/0.95315 to give train size of 10k.  0.04685 = 10000/213451\n",
    "test_size = .5\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(all_train_labels.values.ravel())\n",
    "\n",
    "# Use (train_test_split) to randomize train_users_2 before splitting into train/dev.\n",
    "train_data, dev_data, train_labels, dev_labels = train_test_split(all_train_data, encoded_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "# Final test data for Kaggle submission.\n",
    "test_data = all_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_training_set():\n",
    "    countries = np.unique(encoded_labels)\n",
    "    z = train_data.copy()\n",
    "    z['dest'] = pd.Series(train_labels, index=z.index)\n",
    "    picks = round(len(train_data)/len(countries))\n",
    "    rx = []\n",
    "    for destination in countries:\n",
    "        options = z[z['dest'] == destination].index\n",
    "        ff = np.random.choice(options, picks)\n",
    "        rx.append(z.ix[ff])\n",
    "    \n",
    "    balanced_data = pd.concat(rx) \n",
    "    return balanced_data.iloc[:, 0:-1], balanced_data.iloc[:, -1:].values.ravel()\n",
    "\n",
    "balanced_train_data, balanced_train_labels = create_balanced_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain XGBoost baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'booster':['gbtree', 'gblinear','dart']}\n",
    "xgb = XGBClassifier(nthread=-1)\n",
    "xgb_gs = GridSearchCV(xgb, params, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
    "pipeline = make_pipeline(preprocessor, xgb)\n",
    "pipeline.fit(balanced_train_data, balanced_train_labels.values.ravel())\n",
    "dev_pred = pipeline.predict(dev_data)\n",
    "accuracy = accuracy_score(dev_pred, dev_labels.values.ravel())\n",
    "print('Accuracy: ',accuracy)\n",
    "print(classification_report(dev_pred, dev_labels.values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently configured to used the balanced dataset.  It's broken when trying to propagate the probability between layers forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:02:15\n",
      "Processing layer-2             done | 00:00:01\n",
      "Fit complete                        | 00:02:16\n",
      "\n",
      "Predicting 2 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\_base_functions.py:313: ParameterChangeWarning: Parameter value ('multi:softprob') has changed since model was fitted ('binary:logistic').\n",
      "  (lpar, rpar), ParameterChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer-1             done | 00:00:07\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:08\n",
      "Accuracy:  0.06503569889249106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.13      0.00      0.01      9976\n",
      "         1.0       0.01      0.01      0.01       997\n",
      "         2.0       0.08      0.01      0.01      6914\n",
      "         3.0       0.19      0.01      0.01     39577\n",
      "         4.0       0.13      0.03      0.06      9820\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.18      0.02      0.03     14465\n",
      "         7.0       0.08      0.47      0.14     11171\n",
      "         8.0       0.00      0.00      0.00         0\n",
      "         9.0       0.00      0.00      0.00       180\n",
      "        10.0       0.00      0.00      0.00         0\n",
      "        11.0       0.16      0.06      0.08     13626\n",
      "\n",
      "   micro avg       0.07      0.07      0.07    106726\n",
      "   macro avg       0.08      0.05      0.03    106726\n",
      "weighted avg       0.16      0.07      0.04    106726\n",
      "\n",
      "Fit data:\n",
      "                                   score-m  score-s   ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  randomforestclassifier       0.00     0.00  43.99  4.37  4.80  0.56\n",
      "layer-1  xgbclassifier                0.00     0.00  52.12  0.05  2.43  0.11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\_base_functions.py:313: ParameterChangeWarning: Parameter value ('multi:softprob') has changed since model was fitted ('binary:logistic').\n",
      "  (lpar, rpar), ParameterChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\_base_functions.py:226: MetricWarning: [randomforestclassifier.0.1] Could not score randomforestclassifier. Details:\n",
      "ValueError(\"Classification metrics can't handle a mix of multiclass and continuous-multioutput targets\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\_base_functions.py:226: MetricWarning: [randomforestclassifier.0.2] Could not score randomforestclassifier. Details:\n",
      "ValueError(\"Classification metrics can't handle a mix of multiclass and continuous-multioutput targets\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\_base_functions.py:226: MetricWarning: [xgbclassifier.0.2] Could not score xgbclassifier. Details:\n",
      "ValueError(\"Classification metrics can't handle a mix of multiclass and continuous-multioutput targets\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "c:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\_base_functions.py:226: MetricWarning: [xgbclassifier.0.1] Could not score xgbclassifier. Details:\n",
      "ValueError(\"Classification metrics can't handle a mix of multiclass and continuous-multioutput targets\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:02:23\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index (181) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-3870833131ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mstacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mstacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-185-3870833131ed>\u001b[0m in \u001b[0;36mstacking\u001b[1;34m(propagate, proba)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Fit ensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbalanced_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbalanced_train_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdev_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\ensemble\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;31m# fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\ensemble\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m         with ParallelProcessing(self.backend, self.n_jobs,\n\u001b[0;32m    157\u001b[0m                                 max(self.verbose - 4, 0)) as manager:\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(self, caller, job, X, y, path, return_preds, warm_start, split, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[0mjob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m             return_preds=return_preds, split=split, stack=True)\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaller\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, caller, out, **kwargs)\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreturn_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36m_partial_process\u001b[1;34m(self, task, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__no_output__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_feature_prop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_propagate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_propagate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36m_propagate_features\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# Need to populate propagated features using scipy sparse hstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             self.job.predict_out = hstack(\n\u001b[1;32m--> 758\u001b[1;33m                 [p_in[r:, task.propagate_features],\n\u001b[0m\u001b[0;32m    759\u001b[0m                  p_out[:, task.n_feature_prop:]]\n\u001b[0;32m    760\u001b[0m             ).tolil()\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;31m# row is slice, col is sequence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m        \u001b[1;31m# [1:2,[1,2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m                 \u001b[0msliced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mextractor\u001b[1;34m(indices, N)\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[0mmin_indx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmin_indx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\christmi\\data-sci\\common\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[1;34m(indices, N)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mmax_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index (%d) out of range'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mmin_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index (181) out of range"
     ]
    }
   ],
   "source": [
    "def stacking(propagate=None, proba=None):\n",
    "    seed = 142\n",
    "    \n",
    "    # --- Build ---\n",
    "    # Passing a scoring function will create cv scores during fitting\n",
    "    # the scorer should be a simple function accepting to vectors and returning a scalar\n",
    "    ensemble = SuperLearner(scorer=accuracy_score, random_state=seed, verbose=2)\n",
    "    pf = False\n",
    "    if propagate:\n",
    "        pf = list(range(preprocessor.fit_transform(balanced_train_data).shape[1]))\n",
    "    # Build the first layer\n",
    "    ensemble.add([\n",
    "        RandomForestClassifier(random_state=seed,n_estimators=300, max_depth=10),\n",
    "        XGBClassifier()\n",
    "    ],\n",
    "        #preprocessing=[preprocessor],\n",
    "        propagate_features=pf,\n",
    "        proba=proba)\n",
    "\n",
    "    # Attach the final meta estimator\n",
    "    ensemble.add_meta(LogisticRegression())\n",
    "\n",
    "    # --- Use ---\n",
    "\n",
    "    # Fit ensemble\n",
    "    pipeline = make_pipeline(preprocessor, ensemble)\n",
    "    pipeline.fit(balanced_train_data, balanced_train_labels)\n",
    "    \n",
    "    dev_pred = pipeline.predict(dev_data)\n",
    "    accuracy = accuracy_score(dev_pred, dev_labels)\n",
    "\n",
    "    #ensemble.fit(train_data, train_labels)\n",
    "\n",
    "    # Predict\n",
    "    #preds = ensemble.predict(dev_data)\n",
    "    print('Accuracy: ',accuracy)\n",
    "    print(classification_report(dev_pred, dev_labels))\n",
    "    print(\"Fit data:\\n%r\" % ensemble.data)\n",
    "    #print(\"Prediction score: %.3f\" % accuracy_score(preds, dev_labels))\n",
    "\n",
    "stacking(False,False)\n",
    "stacking(True,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sci-common",
   "language": "python",
   "name": "data-sci-common"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
